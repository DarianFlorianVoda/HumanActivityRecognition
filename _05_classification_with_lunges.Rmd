---
title: "R Notebook - Final Classification Short"
output:
  html_document:
    df_print: paged
---

## Used libaries:

```{r}
library(mosaic)
library(plotly)
library(GGally)
library(dplyr)
library(rpart)
library(caret)
library(psych)
library(ggplot2)
library(ggcorrplot)
library(rela)
```


### 1. Read all samples and combine them

```{r}
# Delete all variables
rm( list = ls() )
```

```{r}
read_idle = read.csv("02_Lunges/01_Idle.csv")
idle_data <- data.frame(read_idle)

read_run = read.csv("02_Lunges/02_Running.csv")
run_data <- data.frame(read_run)

read_lunge= read.csv("02_Lunges/03_Lunge.csv")
lunge_data <- data.frame(read_lunge)

read_siu = read.csv("02_Lunges/04_Siu.csv")
siu_data <- data.frame(read_siu)
```

Rename ID correctly:
```{r}
names(idle_data)[1] <- "ID"
names(run_data)[1] <- "ID"
names(lunge_data)[1] <- "ID"
names(siu_data)[1] <- "ID"
```

#### Combined data

Overall in total there are 8985 rows

So in the dab data for Orientation.X and Orientation.Z we have the wrong data type. <chr> instead of <dbl>

Basically we can't scale before converting to numeric



```{r}
idle_run <- rbind(idle_data, run_data)
irun_lunge <- rbind(idle_run, lunge_data)
motion_data <- rbind(irun_lunge, siu_data)
```

```{r}
idle_run$Orientation.X <- as.numeric(idle_run$Orientation.X)
colSums(is.na(idle_run))
```



### 2. Do some Exploratory Data Analysis (EDA) on whole data:
```{r}
motion_data_all <- data.frame(motion_data)
# Remove Magnetic, because there are many NA's in it
motion_data_all <- motion_data_all[,!names(motion_data_all) %in% c("MagneticField.X")]
motion_data_all <- motion_data_all[,!names(motion_data_all) %in% c("MagneticField.Y")]
motion_data_all <- motion_data_all[,!names(motion_data_all) %in% c("MagneticField.Z")]

# Convert columns to correct type
motion_data_all$Category <- as.factor(motion_data_all$Category)
motion_data_all$Acceleration.X <- as.numeric(motion_data_all$Acceleration.X)
motion_data_all$Orientation.X <- as.numeric(motion_data_all$Orientation.X)
motion_data_all$Orientation.Z <- as.numeric(motion_data_all$Orientation.Z)
```
More NA's found after convertion

```{r}
colSums(is.na(motion_data_all))
```

Remove the NA's

About 8584 rows left

```{r}
motion_data_all <- na.omit(motion_data_all)
colSums(is.na(motion_data_all))
```

Scale the data:
```{r}
quant_var <- select(motion_data_all, c(6:14))
cat_var <- select(motion_data_all, c(3))

quant_var <- scale(quant_var)
motion_data_scale <- cbind(cat_var, quant_var)
motion_data_scale
```


```{r}
motion_data_box <- select(motion_data_scale, c("Acceleration.X","Acceleration.Y","Acceleration.Z","AngularVelocity.X","AngularVelocity.Y","AngularVelocity.Z"))
boxplot(motion_data_box) +
   scale_x_discrete(guide = guide_axis(angle = 90))
  #geom_violin(trim = FALSE) +
  #geom_boxplot() 
  #theme_minimal()
```



Train with data from Ahmed, Tobias, Saghar and Ronaldo
```{r}
#motion_data_part <- subset(motion_data_all, Author == "Ahmed" | Author == "Tobias" | Author == "Saghar" | Author == "Ronaldo") #+ subset(motion_data_all, Author == "Tobias")
#motion_data_unknown <- subset(motion_data, Author == "Regan" | Author == "Darian") # 33 %

motion_data_part <- subset(motion_data_all, Author == "Ahmed" | Author == "Tobias"| Author == "Ronaldo"| Author == "Regan") 
motion_data_test <- subset(motion_data_all, Author == "Saghar")
```

```{r}
colSums(is.na(motion_data_part))
```

```{r}
# For statistics
motion_data_all_stat <- data.frame(motion_data_all)
# Remove unrelevant columns
motion_data_all <- motion_data_all[,!names(motion_data_all) %in% c("ID", "Acceleration.Timestamp", "Author", "Sample")]
```


Write merged cleaned data to file:

```{r}
write.csv(motion_data_all, "All Samples Clean.csv", row.names = FALSE)
```

#### Category data distribution

Stacked bar chart:

Seems like Darian and Ahmed have more compared to the others more motion data

```{r}
cat_count <- group_by(motion_data_all_stat, Author, Category) %>%
  summarize(count=n())
```

```{r}
stack_bar <- ggplot(cat_count, aes(x = Author, y = count, fill = Category)) +
  geom_bar(stat = "identity") #+
  #geom_text(aes(label = count), vjust = -4.5)

ggplotly(stack_bar)
```
```{r}

ggplot(cat_count, aes(x=Author, y=count, fill=Category)) +
  #geom_histogram(bins=(sqrt(length(cat_count$Category))),fill="white",color="black",aes(y=..density..)) +  
  geom_density(alpha=.3) #+
  #facet_grid()
```

#### Correlation plot for numerical values:

Threshold: 0.2 

Old one: Remaining features: Acceleration.X, Acceleration.Z, Orientation.X, Orientation.Y, Orientation.Z

New one: Remaining features: Acceleration.X, Acceleration.Y, Acceleration.Z, AngularVelocity.X, AngularVelocity.Y, AngularVelocity.Z

We remove the orientation, since everyone had a different phone position

```{r}
motion_data_all_numeric <- data.frame(motion_data_all)
motion_data_all_numeric <- motion_data_all_numeric[,!names(motion_data_all_numeric) %in% c("Category")]

#Was for only for testing -> Darian: Everyone has different position of phone, thats why we should skip Orientation
#motion_data_all_numeric <- motion_data_all_numeric[,!names(motion_data_all_numeric) %in% c("Orientation.X", "Orientation.Y", "Orientation.Z")]
#motion_data_all_numeric$Category <- as.numeric(factor(motion_data_all_numeric$Category))
#motion_data_all_numeric$Category <- as.factor(motion_data_all_numeric$Category)



```


```{r}
# Calculate the correlation matrix of the data frame
cor_matrix <- cor(motion_data_all_numeric)

# Visualize the correlation matrix using ggcorrplot
ggcorrplot(cor_matrix, hc.order = TRUE, type = "lower", 
           lab = TRUE, lab_size = 3, method = "circle")

```


We use only relevant columns for the model training
```{r}
remove_col <- c("ID",  "Acceleration.Timestamp", "Author", "Sample", "Orientation.X", "Orientation.Y", "Orientation.Z")

motion_data_part <- motion_data_part[,!names(motion_data_part) %in% remove_col]
```


```{r}
plot_data <- data.frame(motion_data_test)
plot_data <- plot_data[,!names(plot_data) %in% remove_col]

motion_data_part_numeric <- data.frame(plot_data)
motion_data_part_numeric <- motion_data_part_numeric[,!names(motion_data_part_numeric) %in% c("Category")]

#idle_tobias <- subset(motion_data_tobias[1:5], Category == "Idle")
ggpairs(data=motion_data_part_numeric,aes(color = plot_data$Category), title="Motion pair plot with quantiative variables",
  upper = list(
    continuous = wrap("cor", size = 0.75)
  )
)  
```
```{r}

remove_col <- c("ID",  "Author", "Sample", "Orientation.X", "Orientation.Y", "Orientation.Z")
idle_activity = subset(motion_data, Category == "Running" & Author == "Tobias")
idle_activity <- idle_activity[,!names(idle_activity) %in% remove_col]

#test <- scale_x_datetime(breaks = date_breaks("1 hours"), labels=date_format("%H:%m"), expand = c(0,0))
#test
```

```{r}


idle_plot <- group_by(idle_activity, Category) %>%
  ggplot(aes(x=Acceleration.Timestamp)) +
  labs( x = "Timestamp", y = "Acceleration") +
  geom_line(aes(y = Acceleration.X), color="dark green", alpha = 0.8) +
  geom_line(aes(y = Acceleration.Y), color="light blue", alpha = 0.8) +
  geom_line(aes(y = Acceleration.Z), color="dark orange", alpha = 0.8) 
```

```{r}
ggplotly(idle_plot)
```

### 3. Train on whole data with selected features:

Train split: 80 %, Test split: 20 %

Since the features that we selected correlate good and are relevant, we skip the angular velocity
```{r}
set.seed(10)

# Take variables from correlation analysis
feature_selection <- motion_data_part#[,c("Category", "Acceleration.X", "Acceleration.Y", "Acceleration.Z")]

train_index_all <- createDataPartition(feature_selection$Category, p =0.80, list = FALSE)
train_data_all<-feature_selection[train_index_all, ]
test_data_all<-feature_selection[-train_index_all, ]
```

#### Accuracy on train data with rf: 81.56 % without orientation


```{r}
set.seed(6)
# 6: 89.8 %
control_par <- trainControl(method = "cv", number=4)
model_rf_all <- train(Category~.,
                      data=train_data_all, 
                      "rf",
                      trControl = control_par
                      )

model_rf_all
```

Random forest with cross validation 4 fold
```{r}
cm_train_data <- confusionMatrix(model_rf_all)
cm_train_data
```

 
#### Accuracy on testing data with rf and cv: 83.37 % without orientation

```{r}
set.seed(6)
## Generate predictions
rf_all_pred_test <- predict(model_rf_all,test_data_all) 
        
## Print the accuracy
accuracy <- mean(rf_all_pred_test == test_data_all$Category)*100
accuracy
```

```{r}
cm_test_data <- confusionMatrix(rf_all_pred_test, test_data_all$Category)
cm_test_data
```

```{r}
plt <- as.data.frame(cm_test_data$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

rf_conf_mat <- ggplot(plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="#009194") +
        labs(x = "Prediction",y = "Reference") +
        scale_y_discrete(labels=c("Dab","Idle","Running","Siu")) +
        scale_x_discrete(labels=c("Siu", "Running", "Idle", "Dab")) 
        

ggplotly(rf_conf_mat)
```

### 6. Now test the best model from dab on unkown data and compare accuracy



```{r}
remove_col <- c("ID",  "Acceleration.Timestamp", "Author", "Orientation.X", "Orientation.Y", "Orientation.Z")
motion_data_test <- motion_data_test[,!names(motion_data_test) %in% remove_col]
motion_data_test$Sample <- as.numeric(as.factor(motion_data_test$Sample))

unique(motion_data_test$Category)
```
Dab: 1 - 20
Idle: 11 - 20
Run: 22 - 30
Siu: 31 - 40

```{r}
inspect(motion_data_test)
```

Dab is not recognized at all: 10/10 are missclassified

Idle: 10 / 10 Samples with at least 70 % correct

Running: 10 / 10 Samples with at least 60 % correct

Siu: 9 / 10 Samples with at least 50 % correct

In total we have an avg accuracy of 60 %

```{r}
list_motion_data_unknown = c()

total_accuracy <- 0
average_accuracy <- 0
for(i in 1:length(unique(motion_data_test$Sample))){
  #print(i)
  
  motion_data_unknown <- subset(motion_data_test,Sample == i) # 55.76 %
  ref <- motion_data_unknown$Category[motion_data_unknown$Sample == i]
  motion_data_unknown <- motion_data_unknown[,!names(motion_data_unknown) %in% c("Sample")]
  
  motion_data_no_labels <- data.frame(motion_data_unknown)
  names(motion_data_no_labels)[names(motion_data_no_labels) == "Category"] <- "Category"
  motion_data_no_labels$Category <- ""
  
  
  set.seed(6)
  ## Generate predictions
  rf_dab_pred_new <- predict(object = model_rf_all,newdata = motion_data_no_labels) 
          
  ## Print the accuracy
  accuracy <- mean(rf_dab_pred_new ==  motion_data_unknown$Category )*100
  total_accuracy <- total_accuracy + accuracy
  
  motion_data_no_labels$Category = rf_dab_pred_new

  cm_rf_all <- confusionMatrix(rf_dab_pred_new, motion_data_no_labels$Category)
  #print(cm_rf_all)
  test <- as.data.frame(cm_rf_all$table)
  
  
  print(paste("Reference: ", unique(ref), "Prediction: ", test$Prediction[which.max(test$Freq)], "Accuracy: ", accuracy, sep = " "))

  list_motion_data_unknown <- append(list_motion_data_unknown, motion_data_no_labels)
}

average_accuracy <- total_accuracy / length(unique(motion_data_test$Sample))

print(paste("AVG Accuracy: ", average_accuracy))
```

#### Accuracy on train data with knn: 77.29 % without orientation


```{r}
set.seed(6)
# 6: 89.8 %
control_par <- trainControl(method = "cv", number=4)
model_knn <- train(Category~.,
                      data=train_data_all, 
                      "knn",
                      trControl = control_par,
                      metric = "Accuracy"
                      )

model_knn
```

KNN with cross validation 4 fold
```{r}
cm_train_data <- confusionMatrix(model_knn)
cm_train_data
```

#### Accuracy on testing data with knn and cv: 82.07 % without orientation

```{r}
set.seed(6)
## Generate predictions
knn_all_pred_test <- predict(model_knn,test_data_all) 
        
## Print the accuracy
accuracy <- mean(knn_all_pred_test == test_data_all$Category)*100
accuracy
```

```{r}
cm_test_data <- confusionMatrix(knn_all_pred_test, test_data_all$Category)
cm_test_data
```

```{r}
plt <- as.data.frame(cm_test_data$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

rf_conf_mat <- ggplot(plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="#009194") +
        labs(x = "Prediction",y = "Reference") +
        scale_y_discrete(labels=c("Dab","Idle","Running","Siu")) +
        scale_x_discrete(labels=c("Siu", "Running", "Idle", "Dab")) 
        

ggplotly(rf_conf_mat)
```

### 6. Now test the best model from dab on unkown data and compare accuracy



```{r}
remove_col <- c("ID",  "Acceleration.Timestamp", "Author", "Orientation.X", "Orientation.Y", "Orientation.Z")
motion_data_test <- motion_data_test[,!names(motion_data_test) %in% remove_col]
motion_data_test$Sample <- as.numeric(as.factor(motion_data_test$Sample))

unique(motion_data_test$Category)
```
Dab: 1 - 20
Idle: 11 - 20
Run: 22 - 30
Siu: 31 - 40

```{r}
inspect(motion_data_test)
```

Dab is not recognized at all: 10/10 are missclassified

Idle: 10 / 10 Samples with at least 70 % correct

Running: 10 / 10 Samples with at least 60 % correct

Siu: 9 / 10 Samples with at least 50 % correct

In total we have an avg accuracy of 60 %

```{r}
total_accuracy <- 0
average_accuracy <- 0
for(i in 1:length(unique(motion_data_test$Sample))){
  #print(i)
  
  motion_data_unknown <- subset(motion_data_test,Sample == i) # 55.76 %
  ref <- motion_data_unknown$Category[motion_data_unknown$Sample == i]
  motion_data_unknown <- motion_data_unknown[,!names(motion_data_unknown) %in% c("Sample")]
  
  motion_data_no_labels <- data.frame(motion_data_unknown)
  names(motion_data_no_labels)[names(motion_data_no_labels) == "Category"] <- "Category"
  motion_data_no_labels$Category <- ""
  
  
  set.seed(6)
  ## Generate predictions
  knn_pred_new <- predict(object = model_knn,newdata = motion_data_no_labels) 
          
  ## Print the accuracy
  accuracy <- mean(knn_pred_new ==  motion_data_unknown$Category )*100
  total_accuracy <- total_accuracy + accuracy
  
  motion_data_no_labels$Category = knn_pred_new

  cm_rf_all <- confusionMatrix(knn_pred_new, motion_data_no_labels$Category)
  #print(cm_rf_all)
  test <- as.data.frame(cm_rf_all$table)
  
  
  print(paste("Reference: ", unique(ref), "Prediction: ", test$Prediction[which.max(test$Freq)], "Accuracy: ", accuracy, sep = " "))
}

average_accuracy <- total_accuracy / length(unique(motion_data_test$Sample))

average_accuracy
```

#### Accuracy on train data with rpart: 55.69 % without orientation


```{r}
set.seed(6)
# 6: 89.8 %
control_par <- trainControl(method = "cv", number=4)
model_rpart <- train(Category~.,
                      data=train_data_all, 
                      "rpart",
                      trControl = control_par,
                      metric = "Accuracy"
                      )

model_rpart
```

```{r}
# Basic plot for a decision tree
  plot(model_rpart$finalModel,branch = T, margin = 0.1)
  text(model_rpart$finalModel)
```

Rpart with cross validation 4 fold
```{r}
cm_train_data <- confusionMatrix(model_rpart)
cm_train_data
```

#### Accuracy on testing data with rpart and cv: 52.07 % without orientation

```{r}
set.seed(6)
## Generate predictions
rpart_all_pred_test <- predict(model_rpart,test_data_all) 
        
## Print the accuracy
accuracy <- mean(rpart_all_pred_test == test_data_all$Category)*100
accuracy
```

```{r}
cm_test_data <- confusionMatrix(rpart_all_pred_test, test_data_all$Category)
cm_test_data
```

```{r}
plt <- as.data.frame(cm_test_data$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

rf_conf_mat <- ggplot(plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="#009194") +
        labs(x = "Prediction",y = "Reference") +
        scale_y_discrete(labels=c("Dab","Idle","Running","Siu")) +
        scale_x_discrete(labels=c("Siu", "Running", "Idle", "Dab")) 
        

ggplotly(rf_conf_mat)
```

### 6. Now test the rpart model on unkown data and compare accuracy



```{r}
remove_col <- c("ID",  "Acceleration.Timestamp", "Author", "Orientation.X", "Orientation.Y", "Orientation.Z")
motion_data_test <- motion_data_test[,!names(motion_data_test) %in% remove_col]
motion_data_test$Sample <- as.numeric(as.factor(motion_data_test$Sample))

unique(motion_data_test$Category)
```
Dab: 1 - 20
Idle: 11 - 20
Run: 22 - 30
Siu: 31 - 40

```{r}
inspect(motion_data_test)
```

Dab is not recognized at all: 10/10 are missclassified

Idle: 10 / 10 Samples with at least 70 % correct

Running: 10 / 10 Samples with at least 60 % correct

Siu: 9 / 10 Samples with at least 50 % correct

In total we have an avg accuracy of 60 %

```{r}
total_accuracy <- 0
average_accuracy <- 0
for(i in 1:length(unique(motion_data_test$Sample))){
  #print(i)
  
  motion_data_unknown <- subset(motion_data_test,Sample == i) # 55.76 %
  ref <- motion_data_unknown$Category[motion_data_unknown$Sample == i]
  motion_data_unknown <- motion_data_unknown[,!names(motion_data_unknown) %in% c("Sample")]
  
  motion_data_no_labels <- data.frame(motion_data_unknown)
  names(motion_data_no_labels)[names(motion_data_no_labels) == "Category"] <- "Category"
  motion_data_no_labels$Category <- ""
  
  
  set.seed(6)
  ## Generate predictions
  rpart_pred_new <- predict(object = model_rpart,newdata = motion_data_no_labels) 
          
  ## Print the accuracy
  accuracy <- mean(rpart_pred_new ==  motion_data_unknown$Category )*100
  total_accuracy <- total_accuracy + accuracy
  
  motion_data_no_labels$Category = rpart_pred_new

  cm_rf_all <- confusionMatrix(rpart_pred_new, motion_data_no_labels$Category)
  #print(cm_rf_all)
  test <- as.data.frame(cm_rf_all$table)
  
  
  print(paste("Reference: ", unique(ref), "Prediction: ", test$Prediction[which.max(test$Freq)], "Accuracy: ", accuracy, sep = " "))
}

average_accuracy <- total_accuracy / length(unique(motion_data_test$Sample))

average_accuracy
```

This was used for dab:

Good correlation between:

* Orientation.X and Orientation.Y with 0.56

* Orientation.Z and Orientation.Y with 0.48

* Category and Orientation.Y with 0.43

* Orientation.Z and Orientation.X with 0.54

Angular Velocity is quite independent compared to other variables, but we still included it, to determine the activities better.

Since everyone used another phone position, we removed the orientation, because it also didn't really improve the model accuracy.

We also remove magnetic field, because there were a lot of NA's and even by using data were we didn't have NA's it, the models didn't really improve with it. About 40 % on unseen data.

In total we tried three different models: Random forest, KNN and Rpart (Decision Tree).

Accuracies:

* Prediction with random forest: Train data: 81.56 %, Test data: 83.37 % Unseen data: 60.48 %

* Prediction with knn: Train data: 77.29 %, Test data: 82.08 % Unseen data: 59.52 %

* Prediction with rpart: Train data: 55.69 %, Test data: 52.07 % Unseen data: 48.50 %

Classification: 

* The problem is that the models do not recognize dab at all. 

* The reason for that is, because Dab is kinda included into Siu.

* That's why they also missclassified Dab with Siu.

So, we decided to use another acitivity called lunge and train test the models.

